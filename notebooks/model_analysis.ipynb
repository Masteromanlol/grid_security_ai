{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437700a2",
   "metadata": {},
   "source": [
    "# Power Grid Security Model Analysis\n",
    "\n",
    "This notebook analyzes the performance of our trained security classification model for the power grid contingency analysis. We'll look at:\n",
    "\n",
    "1. Feature importance and relationships\n",
    "2. Failure mode analysis\n",
    "3. Model performance metrics and validation\n",
    "4. Grid metric distributions by failure type\n",
    "\n",
    "First, let's import the necessary libraries and load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f9ab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.conda (Python 3.11.14)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n .conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from grid_ai.features import prepare_feature_matrix\n",
    "from grid_ai.ml_pipeline import SecurityClassificationPipeline\n",
    "from grid_ai.visualization import (\n",
    "    plot_confusion_matrix, plot_roc_curve,\n",
    "    plot_feature_importance, plot_grid_metrics,\n",
    "    plot_failure_types\n",
    ")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe4cde",
   "metadata": {},
   "source": [
    "## Load Data and Model\n",
    "\n",
    "Let's load our trained model and the dataset we used for training. We'll reconstruct the feature matrix to analyze both the raw data and model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and model\n",
    "data_path = 'data/processed/case_1354_small_aggregated.pkl'\n",
    "model_path = 'models/case_1354_small_rf.pkl'\n",
    "\n",
    "# Load results\n",
    "results = pd.read_pickle(data_path)\n",
    "\n",
    "# Get network structure information\n",
    "net_structure = {\n",
    "    'n_buses': len(results[0]['bus_results']),\n",
    "    'n_lines': len(results[0]['line_results']),\n",
    "    'n_trafos': len(results[0]['trafo_results']),\n",
    "    'edges': [(int(row['from_bus']), int(row['to_bus'])) \n",
    "             for _, row in results[0]['line_results'].iterrows()]\n",
    "}\n",
    "\n",
    "# Prepare feature matrix\n",
    "df = prepare_feature_matrix(results, net_structure)\n",
    "\n",
    "# Load trained model\n",
    "with open(model_path, 'rb') as f:\n",
    "    pipeline = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(df)} samples\")\n",
    "print(\"\\nFeature matrix shape:\", df.shape)\n",
    "print(\"\\nFailure distribution:\")\n",
    "print(df['failed'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df0ca8",
   "metadata": {},
   "source": [
    "## Feature Analysis\n",
    "\n",
    "Let's analyze the importance of different features in predicting contingency outcomes and their relationships with failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f07d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and plot feature importance\n",
    "importance = pipeline.get_feature_importance()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_feature_importance(importance, top_n=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top 10 most important features\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ba8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grid metrics distribution by failure status\n",
    "numeric_features = [\n",
    "    'voltage_mean', 'voltage_std', 'voltage_min', 'voltage_max',\n",
    "    'line_loading_mean', 'line_loading_std', 'line_loading_max',\n",
    "    'total_p_mw', 'total_q_mvar', 'losses_mw'\n",
    "]\n",
    "\n",
    "plot_grid_metrics(df[numeric_features + ['failed']], numeric_features)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa251aed",
   "metadata": {},
   "source": [
    "## Failure Mode Analysis\n",
    "\n",
    "Let's analyze the different types of failures and their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8676abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of failure types\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_failure_types(df)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze failure rates by component type\n",
    "failure_by_type = pd.crosstab(\n",
    "    df['contingency'].apply(lambda x: x['type']),\n",
    "    df['failed'],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "print(\"\\nFailure rates by component type:\")\n",
    "print(failure_by_type)\n",
    "\n",
    "# Show some statistics about isolated buses\n",
    "if 'isolated_buses' in df.columns:\n",
    "    isolated_stats = df[df['has_isolated_buses']].groupby(\n",
    "        df['contingency'].apply(lambda x: x['type'])\n",
    "    )['isolated_buses'].agg(['count', 'mean', 'median', 'max'])\n",
    "    \n",
    "    print(\"\\nIsolated buses statistics by component type:\")\n",
    "    print(isolated_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d61c2",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "Let's evaluate the model's performance in detail, including cross-validation results and ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cross-validation scores\n",
    "cv_scores = pipeline.cross_validate(\n",
    "    df[pipeline.feature_names],\n",
    "    df['failed']\n",
    ")\n",
    "\n",
    "print(\"Cross-validation scores:\")\n",
    "for metric, scores in cv_scores.items():\n",
    "    print(f\"{metric:20s}: {np.mean(scores):.3f} (+/- {np.std(scores):.3f})\")\n",
    "\n",
    "# Get predictions on full dataset\n",
    "y_pred = pipeline.predict(df[pipeline.feature_names])\n",
    "y_prob = pipeline.predict_proba(df[pipeline.feature_names])[:, 1]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(df['failed'], y_pred)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(df['failed'], y_prob)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate performance by component type\n",
    "performance_by_type = []\n",
    "for comp_type in df['contingency'].apply(lambda x: x['type']).unique():\n",
    "    mask = df['contingency'].apply(lambda x: x['type']) == comp_type\n",
    "    metrics = pipeline.evaluate(\n",
    "        df[mask][pipeline.feature_names],\n",
    "        df[mask]['failed']\n",
    "    )\n",
    "    performance_by_type.append({\n",
    "        'type': comp_type,\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'f1': metrics['f1']\n",
    "    })\n",
    "\n",
    "print(\"\\nPerformance by component type:\")\n",
    "print(pd.DataFrame(performance_by_type).set_index('type').round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grid_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
